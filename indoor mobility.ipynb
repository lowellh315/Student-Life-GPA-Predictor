{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import *\n",
    "import glob\n",
    "import scipy \n",
    "from datetime import datetime as dt\n",
    "import sklearn\n",
    "sns.style = 'darkgrid'\n",
    "import ruptures as rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intervals(activity_df, locations_df): \n",
    "    \"\"\"\n",
    "    given an activity_dataframe and a locations dataframe takes the first step for calculating\n",
    "    the indoor mobility, or average activity inference for times where the user was inside.\n",
    "    This function assumes that locations_df and activity_df are already ordered by date. \n",
    "    This initial function outputs two lists: \n",
    "        loc_intervals containing the time intervals where locations are inside\n",
    "        activities_intervals contianing the time intervals for each activity inference so the activities can be \n",
    "        processed with a reasonable runtime. \n",
    "    \"\"\"\n",
    "    # create a dataframe of all indoor locations\n",
    "    indoor_booleans = locations_df['location'].apply(lambda l: l[:2]) == 'in'\n",
    "    indoor_locations = locations_df[indoor_booleans]\n",
    "    \n",
    "    # the following code creates a list of tuples which represent the ranges of timestamps where users were inside\n",
    "    start_timestamp = None\n",
    "    loc_intervals = []\n",
    "    for i in indoor_locations.index:\n",
    "        current_timestamp = indoor_locations.loc[i]['timestamp']\n",
    "        if start_timestamp is None: \n",
    "            start_timestamp = current_timestamp\n",
    "            \n",
    "        # don't consider locations continuous when sensed more than 1/2 hour apart\n",
    "        if current_timestamp > start_timestamp + 1800:\n",
    "            loc_intervals.append((start_timestamp, current_timestamp))\n",
    "            start_timestamp = None\n",
    "            continue\n",
    "        try: \n",
    "            # if the next index is not inside, we go to the except loop, otherwise continue\n",
    "            indoor_locations.loc[i + 1]\n",
    "            continue\n",
    "        except: \n",
    "            # in the event the next index is not inside, this is the end of the time range so we append that to the intervals\n",
    "            loc_intervals.append((start_timestamp, current_timestamp))\n",
    "            start_timestamp = None\n",
    "            continue\n",
    "\n",
    "    # the next block of code reduces the activity intervals down to a list of tuples, each tuple containing a start\n",
    "    # and end timestamp, along with the activity inference for that range of time. This will vastly reduce the number of\n",
    "    # iterations we have to do to loop through activities in the future. \n",
    "    activities_intervals = [] \n",
    "    start_timestamp = None \n",
    "    act = activity_df.iloc[0]\n",
    "    \n",
    "    for i in activity_df.index:\n",
    "        # this try except loop takes care of the last element\n",
    "        try: \n",
    "            next_act = activity_df.loc[i+1]\n",
    "        except: \n",
    "            continue\n",
    "        \n",
    "        # the current and next activity inferenecs\n",
    "        inf = act[' activity inference']\n",
    "        next_inf = next_act[' activity inference']\n",
    "        \n",
    "        # if the start timestamp is none, we set it to the current timestamp\n",
    "        if start_timestamp is None: \n",
    "            start_timestamp = act['timestamp']\n",
    "\n",
    "        # if the activity inference changes, make the interval break\n",
    "        # also, if the timestamps are more than a half hour apart, don't consider this a continuous interval\n",
    "        if inf != next_inf or next_act['timestamp'] > act['timestamp'] + 1800: \n",
    "            end_timestamp = act['timestamp']\n",
    "            activities_intervals.append((start_timestamp, end_timestamp, inf))\n",
    "            start_timestamp = next_act['timestamp']\n",
    "        act = next_act\n",
    "\n",
    "    \"\"\"\n",
    "    at this point we have two sets of intervals, loc_intervals containing the time intervals where locations are inside\n",
    "    and activities_intervals contianing the time intervals for each activity inference so the activities can be \n",
    "    processed with a reasonable runtime. Now, the goal is to match up the intervals where the timestamps for activities\n",
    "    overlap with timestamps from indoor locations\n",
    "    \"\"\"\n",
    "               \n",
    "    return loc_intervals, activities_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indoor_mobility(loc_intervals, activity_intervals): \n",
    "    \"\"\"\n",
    "    given the wifi and activity intervals as described above, calculates the indoor mobility for the user given those\n",
    "    intervals\n",
    "    \"\"\"\n",
    "    # counter tracks the index of activity_intervals we are currently on\n",
    "    counter = 0 \n",
    "    indoor_mobility = pd.DataFrame()\n",
    "    \n",
    "    for inter in loc_intervals: \n",
    "        \n",
    "        loc_inter_start = inter[0]\n",
    "        loc_inter_end = inter[1]\n",
    "        \n",
    "        if loc_inter_start is None: \n",
    "            print(inter)\n",
    "        done = False\n",
    "        \n",
    "        while done is False: \n",
    "            try: \n",
    "                act_inter_start = activity_intervals[counter][0]\n",
    "            except: \n",
    "                break\n",
    "            act_inter_end = activity_intervals[counter][1]\n",
    "\n",
    "            if act_inter_end < loc_inter_start: \n",
    "                counter += 1\n",
    "                continue\n",
    "                \n",
    "            # if the start of the activity interval is greater than that of the location interval, we're done with this loc.\n",
    "            elif act_inter_start > loc_inter_end: \n",
    "                done = True\n",
    "                continue\n",
    "\n",
    "            im_start = max(act_inter_start, loc_inter_start)\n",
    "            \n",
    "            if act_inter_end <= loc_inter_end: \n",
    "                im_end = act_inter_end\n",
    "                \n",
    "                temp = pd.DataFrame({'start timestamp': im_start, \n",
    "                                 'end timestamp': im_end, \n",
    "                                 'duration (s)': [im_end - im_start],\n",
    "                                 'activity inference': [activity_intervals[counter][2]]})\n",
    "        \n",
    "                indoor_mobility = indoor_mobility.append(temp, ignore_index = True)\n",
    "                counter += 1\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            if act_inter_end > loc_inter_end: \n",
    "                im_end = loc_inter_end\n",
    "                done = True\n",
    "                \n",
    "            temp = pd.DataFrame({'start timestamp': im_start, \n",
    "                                 'end timestamp': im_end, \n",
    "                                 'duration (s)': [im_end - im_start],\n",
    "                                 'activity inference': [activity_intervals[counter][2]]})\n",
    "        \n",
    "            indoor_mobility = indoor_mobility.append(temp, ignore_index = True)\n",
    "    \n",
    "    return indoor_mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indoor_mobility_by_day(indoor_mob, act_col): \n",
    "    \"\"\"\n",
    "    given an indoor mobility dataframe, calculate the average indoor mobility per day the dataframe.\n",
    "    returns a dataframe contianing avg indoor mobility per day and uid\n",
    "    \"\"\"\n",
    "    agg_df = pd.DataFrame()\n",
    "    for day in indoor_mob['day'].unique(): \n",
    "        total_duration = 0\n",
    "        aggregate_act = 0\n",
    "        # average activity inference per day = duration*activity inference/total duration\n",
    "        for row in indoor_mob[['duration (s)', act_col]][indoor_mob['day'] == day].values:\n",
    "            total_duration += row[0]\n",
    "            aggregate_act += row[0]*row[1]\n",
    "        aggregate_act = aggregate_act/total_duration\n",
    "\n",
    "        agg_df = agg_df.append(pd.DataFrame({'average indoor mobility': [aggregate_act], \n",
    "                                    'day': [day]}))\n",
    "    agg_df['uid'] = indoor_mob.uid.unique()[0]\n",
    "    \n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_indoor_mobility_process(activities, wifi_locations): \n",
    "    \"\"\"\n",
    "    combines the three functions above to process indoor mobility for all users given the activitites and wifi locations\n",
    "    dataframes. Returns the indoor mobility aggregated for all users\n",
    "    \"\"\"\n",
    "    # initialize indoor mobility dataframes\n",
    "    indoor_mob = pd.DataFrame() \n",
    "    day_im = pd.DataFrame()\n",
    "    evening_im = pd.DataFrame()\n",
    "    night_im = pd.DataFrame()\n",
    "    \n",
    "    # take the intersection of the uids from the two dataframes\n",
    "    uids = set(activities.uid.unique()) | set(wifi_locations.uid.unique())\n",
    "    # loop through every uid\n",
    "    for uid in uids: \n",
    "        print(uid)\n",
    "        # find activity and location intervals for the uid\n",
    "        loc_int, act_int = find_intervals(activities[activities['uid'] == uid],\n",
    "                                          wifi_locations[wifi_locations['uid'] == uid])\n",
    "        \n",
    "        # find the overlapping indoor mobility dataframe (containing duration inside + activity inference as columns)\n",
    "        im = indoor_mobility(loc_int, act_int)\n",
    "        im['uid'] = uid\n",
    "        im['time'] = pd.to_datetime(im['start timestamp'], unit = 's') \n",
    "        im['date'] = im['time'].apply(lambda x: dt.strftime(x, '%Y-%m-%d'))\n",
    "        \n",
    "        # reuse the activity function to make epochs and reformat the indoor mobility grouping by day\n",
    "        tot, day, evening, night = aggregate_activities(activity_epochs(im))\n",
    "        \n",
    "        # apply the formula \n",
    "        indoor_mob = indoor_mob.append(indoor_mobility_by_day(tot, 'activity inference'), ignore_index = True)\n",
    "        day_im = day_im.append(indoor_mobility_by_day(day, 'activity inference'), ignore_index = True)\n",
    "        evening_im = evening_im.append(indoor_mobility_by_day(evening, 'activity inference'), ignore_index = True)\n",
    "        night_im = night_im.append(indoor_mobility_by_day(night, 'activity inference'), ignore_index = True)\n",
    "        \n",
    "    indoor_mob = indoor_mob.rename(columns = {' activity inference': 'indoor mobility'})\n",
    "    day_im = day_im.rename(columns = {'day activity inference': 'day indoor mobility'})\n",
    "    evening_im = evening_im.rename(columns = {'evening activity inference': 'evening indoor mobility'})\n",
    "    night_im = night_im.rename(columns = {'night activity inference': 'night indoor mobility'})\n",
    "        \n",
    "    return indoor_mob, day_im, evening_im, night_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_activities(activity): \n",
    "    \"\"\"\n",
    "    given input activity dataframe this function organizes that dataframe by day and uid, then returns a total dataframe \n",
    "    along with a dataframe for each epoch - day, evening, and night. \n",
    "    \"\"\"\n",
    "    # This code is a little clunky, but I thought formatting it in a function would take a longer runtime because it would \n",
    "    # require more for loops, and the activity data already takes a long time to process since it is a large dataset. \n",
    "\n",
    "    # the goal of this function is to create a new dataframe with the average activity inference for each day for each user. \n",
    "    # it will also make dataframes \n",
    "\n",
    "    # I will aggregate the data in the folloing data frames\n",
    "    aggreg = pd.DataFrame()\n",
    "    day_aggreg = pd.DataFrame()\n",
    "    evening_aggreg = pd.DataFrame()\n",
    "    night_aggreg = pd.DataFrame()\n",
    "\n",
    "    # loop through each uid\n",
    "    for uid in activity.uid.unique(): \n",
    "\n",
    "        # take the uid specific data, group it by day, find the mean, and then append each dataframe to its respective aggregate.\n",
    "        uid_data = activity[activity['uid'] == uid]\n",
    "        day = uid_data[uid_data['epoch'] == 'Day']\n",
    "        evening = uid_data[uid_data['epoch'] == 'Evening']\n",
    "        night = uid_data[uid_data['epoch'] == 'Night']\n",
    "\n",
    "        uid_data['uid'] = uid\n",
    "        day['uid'] = uid\n",
    "        evening['uid'] = uid\n",
    "        night['uid'] = uid\n",
    "\n",
    "        aggreg = aggreg.append(uid_data)\n",
    "        day_aggreg = day_aggreg.append(day)\n",
    "        evening_aggreg = evening_aggreg.append(evening)\n",
    "        night_aggreg = night_aggreg.append(night)\n",
    "        \n",
    "    # make the columns in each dataframe more descriptive\n",
    "    activity = aggreg\n",
    "    \n",
    "    # make day activities dataframe\n",
    "    day_activity = day_aggreg\n",
    "    day_activity = day_activity.rename(columns = {' activity inference': 'day activity inference'})\n",
    "\n",
    "    # make evening activities dataframe\n",
    "    evening_activity = evening_aggreg\n",
    "    evening_activity = evening_activity.rename(columns = {' activity inference': 'evening activity inference'})\n",
    "\n",
    "    # make night activities dataframe\n",
    "    night_activity = night_aggreg\n",
    "    night_activity = night_activity.rename(columns ={' activity inference': 'night activity inference'})\n",
    "    \n",
    "    return activity, day_activity, evening_activity, night_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(times_tuple):\n",
    "    \"\"\"\n",
    "    input: tuple containing start and end times (in hours on 24 hour scale)\n",
    "    output: the epoch that corresponds to the timestamps\n",
    "    note: we chose to only return timestamps that had both start and end time within a single epoch. An alternative would\n",
    "    be splitting conversations that span multiple epochs into two conversations, one in each epoch, but we decided not to \n",
    "    because that would double count conversations for each user.  \n",
    "    \"\"\"\n",
    "    start = times_tuple[0]\n",
    "    end = times_tuple[1]\n",
    "    \n",
    "    # Day epoch: hours 10 am -6 pm\n",
    "    if (start and end) >= 10 and (start and end) <18 :\n",
    "        return 'Day'\n",
    "    # Night epoch: 12 am - 10 am\n",
    "    elif (start and end)<10:\n",
    "        return 'Night'\n",
    "    # evening epoch: 6 pm - 12 am\n",
    "    elif (start and end) >= 18:\n",
    "        return 'Evening'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_epochs(activity):\n",
    "    # these lines find the day and hour of activity inference\n",
    "    activity['day'] = activity['date'].apply(lambda x: dt.strptime(x, '%Y-%m-%d')).dt.dayofyear\n",
    "\n",
    "    activity['epoch'] = pd.to_datetime(activity['time']).dt.hour\n",
    "\n",
    "    # next, apply the epoch function to find the epoch of each activity\n",
    "    activity['epoch'] = list(zip(activity['epoch'], activity['epoch']))\n",
    "\n",
    "    activity['epoch'] = activity['epoch'].apply(epoch)\n",
    "    \n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = pd.read_csv('tables/activity/activity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wifi_locations = pd.read_csv('tables/wifi_location/wifi_location.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lowell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Lowell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Lowell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u20\n",
      "u19\n",
      "u18\n",
      "u14\n",
      "u54\n",
      "u57\n",
      "u46\n",
      "u10\n",
      "u25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lowell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u24\n",
      "u56\n",
      "u39\n",
      "u53\n",
      "u01\n",
      "u23\n",
      "u50\n",
      "u27\n",
      "u03\n",
      "u35\n",
      "u34\n",
      "u30\n",
      "u08\n",
      "u00\n",
      "u51\n",
      "u12\n",
      "u07\n",
      "u52\n",
      "u22\n",
      "u43\n",
      "u42\n",
      "u41\n",
      "u02\n",
      "u16\n",
      "u47\n",
      "u05\n",
      "u45\n",
      "u17\n",
      "u49\n",
      "u09\n",
      "u32\n",
      "u36\n",
      "u04\n",
      "u58\n",
      "u59\n",
      "u15\n",
      "u33\n",
      "u13\n",
      "u31\n"
     ]
    }
   ],
   "source": [
    "indoor_mob, day_im, evening_im, night_im = final_indoor_mobility_process(activities, wifi_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "indoor_mob.to_csv('dataset/sensing/indoor_mobility/indoor_mobility.csv', index = False)\n",
    "day_im.to_csv('dataset/sensing/indoor_mobility/day_indoor_mobility.csv', index = False)\n",
    "evening_im.to_csv('dataset/sensing/indoor_mobility/evening_indoor_mobility.csv', index = False)\n",
    "night_im.to_csv('dataset/sensing/indoor_mobility/night_indoor_mobility.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05293561418501729"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indoor_mob['average indoor mobility'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_im['average indoor mobility'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
